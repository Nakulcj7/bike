{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nakulcj7/bike/blob/main/Bike_sharing_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -Seoul Bike Sharing Demand Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    -Regression\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bike sharing systems have gained widespread popularity in urban environments, offering a sustainable and efficient mode of transportation. This project focuses on developing a predictive model for bike sharing demand, leveraging historical data, weather conditions, and other relevant factors. The primary goal is to create a robust and accurate prediction system to optimize bike allocation and enhance user experience.There were approximately 8760 records and 14 attributes in the dataset.This dataset contains information on Seoul city's weather conditions (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall)and the number of bikes rented on every hour and the date information."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Nakulcj7/bike/blob/main/Bike_sharing_prediction.ipynb\n"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "It is necessary to make the rental bike avaiable and accessible for the public at the right time as the waiting period shortens.Eventually,providing the city with a stable supply of rental bikes becomes a major concern.The main think to focus here is to predict the bike count required at each hour for a stable supply of rental bikes.\n",
        "\n",
        "\n",
        "The major objective here is to count the rental bikes required on an daily hour basis and also to identify the features which influences the hourly demant for rental bikes."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "YdJyO1iis8tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataset\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/Almabetter/SeoulBikeData.csv\", encoding='ISO-8859-1')"
      ],
      "metadata": {
        "id": "oiY18hAKfd2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "pTDoCgkUtOGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'number of rows : {df.shape[0]}  \\nnumber of columns : {df.shape[1]}')"
      ],
      "metadata": {
        "id": "q9bgooJNiIvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing the statistical summary of the data\n",
        "df.describe(include='all').T"
      ],
      "metadata": {
        "id": "NgLRP7C6ioVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(df[df.duplicated()])"
      ],
      "metadata": {
        "id": "61upOsmEtzgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows that there are no duplicate rows present in the dataset.\n"
      ],
      "metadata": {
        "id": "fHOc-sBEjHqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So it is evident that there is no null values in the dataset.So we can that the dataset is balanced.\n"
      ],
      "metadata": {
        "id": "UWfMp_x1jkxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset provided contains 14 columns and 8760 rows and does not have any missing or duplicate values."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include='all').T\n"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = [ftr for ftr in df.columns if df[ftr].dtype != 'O'] # attributes that are not of Object typer, i.e numerical data\n",
        "categorical_features = [ftr for ftr in df.columns if df[ftr].dtype == 'O']\n",
        "target = ['Rented Bike Count']\n",
        "numerical_features.remove(target[0])"
      ],
      "metadata": {
        "id": "iUobpIdTud3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " This dataset contains information on Seoul city's weather conditions (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall)and the number of bikes rented on every hour and the date information.\n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "\n",
        "*   Date :The date of each observation in the format 'year-month-day'\n",
        "\n",
        "*   Rented Bike count - Count of bikes rented at each hour\n",
        "\n",
        "*   Hour - Hour of the day\n",
        "\n",
        "*   Temperature - Temperature recorded in the city in Celsius (°C).\n",
        "\n",
        "*   Humidity - Relative humidity in %\n",
        "\n",
        "*   \n",
        "Windspeed - Speed of the wind in m/s\n",
        "\n",
        "\n",
        "*   Visibility - measure of distance at which object or light can be clearly discerned in units of 10m\n",
        "*   Dew point temperature - Temperature recorded in the beginning of the day in Celsius(°C).\n",
        "\n",
        "\n",
        "*   Solar radiation - Intensity of sunlight in MJ/m^2\n",
        "\n",
        "\n",
        "*   Rainfall - Amount of rainfall received in mm\n",
        "\n",
        "\n",
        "*   Snowfall - Amount of snowfall received in cm\n",
        "\n",
        "\n",
        "*   Seasons - Season of the year (Winter, Spring, Summer, Autumn)\n",
        "\n",
        "\n",
        "*   Holiday - Whether the day is a Holiday or not (Holiday/No holiday)\n",
        "\n",
        "\n",
        "*   Functional Day -Whether the rental service is available (Yes-Functional hours) or not (No-Non functional hours)\n",
        "\n"
      ],
      "metadata": {
        "id": "QIuQFZnOp5-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Exploratory Data Analysis***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorizing features as numerical and categorical"
      ],
      "metadata": {
        "id": "-2ucuV9Mwv0u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Univariate Analysis"
      ],
      "metadata": {
        "id": "77Jxq4x9w3q-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution of Numerical Features"
      ],
      "metadata": {
        "id": "f0uAUdgTw91f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.figure(figsize=(25, 15))\n",
        "plt.suptitle(\"Distribution Plot\", fontsize=18, y=0.95)\n",
        "\n",
        "for n, ticker in enumerate(numerical_features + target):\n",
        "  # add a new subplot iteratively\n",
        "  ax = plt.subplot(4,3, n + 1)\n",
        "  plt.subplots_adjust(hspace=0.5, wspace=0.3)\n",
        "  # filter df and plot ticker on the new subplot axis\n",
        "  sns.distplot(df[ticker])\n",
        "  plt.axvline(df[ticker].mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "  plt.axvline(df[ticker].median(), color='cyan', linestyle='dashed', linewidth=2)\n",
        "  ax.set_title(ticker.upper())\n",
        "  ax.set_xlabel(\"\")"
      ],
      "metadata": {
        "id": "zfCvA4nMw3Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Other than 'Hour', all numerical features exhibit some resemblance to a normal distribution.\n",
        ".\n",
        "        \n",
        "\n",
        "\n",
        "*   The distribution for numerical features like Rented Bike Count, Solar Radiation and Visibility appear highly skewed, indicating the presence of large outliers.\n",
        "\n"
      ],
      "metadata": {
        "id": "LNtb2YEExw_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.figure(figsize=(25, 15))\n",
        "plt.suptitle(\"Regression Plot\", fontsize=18, y=0.95)\n",
        "\n",
        "for n, ticker in enumerate(numerical_features):\n",
        "  # add a new subplot iteratively\n",
        "\n",
        "  # filter df and plot ticker on the new subplot axis\n",
        "  ax = plt.subplot(4,3, n+1)\n",
        "  plt.subplots_adjust(hspace=0.5, wspace=0.3)\n",
        "  sns.regplot(x=df[ticker],y=df[target],line_kws={\"color\": \"red\"})\n",
        "  ax.set_title(ticker.upper())\n",
        "  ax.set_xlabel(\"\")\n"
      ],
      "metadata": {
        "id": "c_C-Bj4cyNQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction"
      ],
      "metadata": {
        "id": "m4uw-g9mycOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to get deeper insights, we'll be extracting features from the date column. The relevant features extracted will be:\n",
        "\n",
        "1.   Weekend: Boolean variable tells if the day falls on a weekend\n",
        "\n",
        "1.   day of the week\n",
        "2.   Month\n",
        "\n",
        "Features extracted from hour column will be:\n",
        "\n",
        "4.   Day Phase: Morning, Afternoon,Evening and Night\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q69VTC_0yjaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting features from Date column"
      ],
      "metadata": {
        "id": "9V17_qBfzCUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt                                                                                                                                                                                                                                                  #mahinisawesomemate\n",
        "df['Date']=pd.to_datetime(df['Date'],)"
      ],
      "metadata": {
        "id": "NDW-JjIbzFtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(datetime_is_numeric=True)"
      ],
      "metadata": {
        "id": "vBRqZ6RCzPEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data for one year (2017 December 1 to 2018 November 12) is present"
      ],
      "metadata": {
        "id": "RMRt0_CqzUDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('Date').agg({'Hour':'count'}).Hour.unique()"
      ],
      "metadata": {
        "id": "qNI6THcjzW-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 24 logs of bike rental data provided in the dataset"
      ],
      "metadata": {
        "id": "oT5INqerzbdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = df['Date'].dt.day_name()\n",
        "df['Weekend']= a.apply(lambda x : 'Yes' if x=='Saturday' or x=='Sunday' else 'No' ) #tells if the day is a weekday or not\n",
        "df['DayNo'] = df['Date'].dt.dayofweek #Day Number of week\n",
        "df['Day Name'] = df['Date'].dt.day_name()\n",
        "df['Month'] = df['Date'].apply(lambda x : x.month) #returns month from date\n",
        "\n",
        "categorical_features.remove('Date') #Dropping date as necessary features are extracted\n",
        "categorical_features = categorical_features + ['Weekend','Month', 'Day Name']"
      ],
      "metadata": {
        "id": "FsSozVXkzhGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features"
      ],
      "metadata": {
        "id": "8k8Mu64jznQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def phase_day(row):\n",
        "\n",
        "  if 6 <= int(row['Hour']) <=11: #Time between 6am and 11am\n",
        "    return 'Morning'\n",
        "\n",
        "  if 12 <= int(row['Hour'])< 18: #Time between 12 noon and 6pm\n",
        "    return 'AfterNoon'\n",
        "\n",
        "  if 18 <= int(row['Hour'])<=21: #Time between 6pm and 9pm\n",
        "    return 'Evening'\n",
        "\n",
        "  if 22 <= int(row['Hour']) or int(row['Hour']) < 6  : #Time between 10pm and 6am, next day\n",
        "    return 'Night'\n",
        "\n",
        "df['Day Phase'] = df.apply(lambda row: phase_day(row), axis =1)\n",
        "categorical_features.append('Day Phase')"
      ],
      "metadata": {
        "id": "J1JB37xFzurA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since time of the day is cyclic in nature (after 23:59pm it's 00:01am which is 2 minute difference but will be treated as 23 hours and 58 minute difference instead) we are doing sin and cosine transformations"
      ],
      "metadata": {
        "id": "_LZkR1Hcz2kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "for a in ['Hour', 'Month','DayNo']:\n",
        "  b =  2 * math.pi * df[a] / df[a].max()\n",
        "  df['sin ' + a ] = np.sin(b)\n",
        "  df[\"cos \" + a ] = np.cos(b)\n",
        "df.drop('DayNo', inplace=True, axis=1)"
      ],
      "metadata": {
        "id": "7uobSPYbz51e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "ei2EVftAz9z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in categorical_features:\n",
        "  print(col, df[col].unique(), '\\n')"
      ],
      "metadata": {
        "id": "GYiKHkHw0BH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count Plot of Categorical Attributes"
      ],
      "metadata": {
        "id": "Iz8SMt-f0HCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.figure(figsize=(25, 15))\n",
        "plt.suptitle(\"Count Plot\", fontsize=18, y=0.95)\n",
        "\n",
        "for n, ticker in enumerate(categorical_features):\n",
        "  # add a new subplot iteratively\n",
        "\n",
        "  # filter df and plot ticker on the new subplot axis\n",
        "  ax = plt.subplot(4,3, n+1)\n",
        "  plt.subplots_adjust(hspace=0.5, wspace=0.3)\n",
        "  sns.countplot(x=df[ticker])\n",
        "  ax.set_title(ticker.upper())\n",
        "  ax.set_xlabel(\"\")"
      ],
      "metadata": {
        "id": "hlUTNUjb-EGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions**\n",
        "\n",
        "\n",
        "*   What is the trend of Bike Sharing on an average day?\n",
        "\n",
        "*   How do Holidays affect Bike Sharing Demand?\n",
        "*   How do Holidays, Seasons, Weekends and the Month of the year have an effect on this trend?\n",
        "\n",
        "\n",
        "*   How does the Bike Sharing demand fluctuate in different times of the day?(will be done using boxplot)\n",
        "\n"
      ],
      "metadata": {
        "id": "f4elZCjK_NbA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is the trend of Bike Sharing on an average day?"
      ],
      "metadata": {
        "id": "wyTN2ORQ_nBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (16,8))\n",
        "sns.lineplot(x = 'Hour', y= 'Rented Bike Count', data = df)\n",
        "plt.title(\"Average Bike Sharing Demand\")                                                                                                                                                                                                                                                #mahinisawesomemate\n",
        "a = plt.xticks(ticks = np.arange(0,24,1))"
      ],
      "metadata": {
        "id": "jRnMquMz_vQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (16,8))\n",
        "sns.lineplot(x = 'Hour', y= 'Rented Bike Count',hue ='Day Name' , data = df)\n",
        "plt.title(\"Average Bike Sharing Demand on Different days of the Week\")\n",
        "a = plt.xticks(ticks = np.arange(0,24,1))"
      ],
      "metadata": {
        "id": "QPgqvm8o_0Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Number of Bikes Rented increses from 5 am and reaches its first peak at 8am.\n",
        "\n",
        "*   The demand starts raising again at 10 am and reaches the second peak at 6 pm and this is the busiest time of the day.\n",
        "*   The demand keeps decreasing from 6 pm to 4 am next day. 4-5 am is observed to be the quietest hours of the day.\n",
        "\n",
        "\n",
        "*   The mornings are busies on Mondays while evenings are busiest on the last working day, Friday. Late morning and afternoon demand in Bike Sharing is busiest on Saturdays and Sunday\n",
        "\n"
      ],
      "metadata": {
        "id": "pCXoTZSb_6fK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. How do Holidays affect Bike Sharing Demand?"
      ],
      "metadata": {
        "id": "jG0hp5LJAMMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (16,8))\n",
        "sns.lineplot(x = 'Hour', y= 'Rented Bike Count',hue ='Holiday' , data = df)\n",
        "plt.title(\"Bike Sharing Demand: Holidays vs Working Days\")\n",
        "a = plt.xticks(ticks = np.arange(0,24,1))"
      ],
      "metadata": {
        "id": "RduyWo1zATw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Bike Sharing Demands are substantially lowered on Holidays in comparison to Working days\n",
        "*   The peaks aren't identical and the demand is low and increases very gradually. This suggests that the demand is contributed by the Working class people to a notable extent.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r8yllCmrAb7C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. How do Seasons have an effect on this trend?"
      ],
      "metadata": {
        "id": "iVyoZHzfAuv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (16,8))\n",
        "sns.lineplot(x = 'Hour', y= 'Rented Bike Count',hue ='Seasons' , data = df)\n",
        "plt.title(\"Bike Sharing Demand in Different Seasons\")\n",
        "a = plt.xticks(ticks = np.arange(0,24,1))"
      ],
      "metadata": {
        "id": "vjvJTqO4AxLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Winter season recieves the least bike sharing demand of all the seasons while Summer is observed to be the season of maximum bike sharing demand\n",
        "*   The peaks and lows are similar in all the seasons suggesting that the rental routines of the people don't change but the amount of demand certainly does\n",
        "\n"
      ],
      "metadata": {
        "id": "EoB7Niz2A9Wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (16,8))\n",
        "sns.lineplot(x = 'Hour', y= 'Rented Bike Count',hue ='Weekend' , data = df)\n",
        "plt.title(\"Bike Sharing Demand: Weekends vs Weekdays\")\n",
        "a = plt.xticks(ticks = np.arange(0,24,1))"
      ],
      "metadata": {
        "id": "mQiFK-88BHjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The afternoons and late-nights are busier in the weekends as compared to the weekdays while the mornings and late evenings appear quieter"
      ],
      "metadata": {
        "id": "eGyD59WMBK8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. How does the Bike Sharing demand fluctuate in different times of the day?"
      ],
      "metadata": {
        "id": "R0BjM0CBBOZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.suptitle('Bikes Rented Fluctuation on Different Times of the Day', fontsize=18, y=0.95)                                                                                                                                                                                                                                                #mahinisawesomemate\n",
        "\n",
        "for n,time in enumerate(df['Day Phase'].unique()):\n",
        "  a = df[df['Day Phase']== time]\n",
        "  ax = plt.subplot(1,4, n+1)\n",
        "  plt.subplots_adjust(hspace=0.5, wspace=0.5)\n",
        "  sns.boxplot(y= 'Rented Bike Count', data = a)\n",
        "  ax.set_title(time.upper())\n",
        "  ax.set_ylabel(\"\")"
      ],
      "metadata": {
        "id": "_1yaOQ_hBRLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most bike sharing demand is happened in the evening\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ls-24ze_Bguk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation Heatmap"
      ],
      "metadata": {
        "id": "p8F1OOzZBsqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,10))\n",
        "#Plotting COrrelation HEATMAP\n",
        "sns.heatmap(df.corr(), annot = True)"
      ],
      "metadata": {
        "id": "iD7F8bN1BwwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Strong correlation of 0.91 observed between Hour and Dew point temperatur\n",
        "*   Rented Bike count has a positive correlation with the Temperature and Hour of the day\n",
        "\n"
      ],
      "metadata": {
        "id": "WRJVag4JB2PB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping feature: Date as this will no longer be necessary as necessary features have been extracted from it"
      ],
      "metadata": {
        "id": "E_8HcNsXCJQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(columns=['Date'],axis=1)"
      ],
      "metadata": {
        "id": "feXwvy-7CNIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "kR8Sz58qDN5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25, 10))\n",
        "plt.suptitle('BOX PLOT of Numerical Features', fontsize=18, y=0.95)\n",
        "\n",
        "#Looping through numerical features and looking for outliers using BOX PLOT\n",
        "for n, ticker in enumerate(numerical_features + target):\n",
        "  ax = plt.subplot(4,3, n+1)\n",
        "  plt.subplots_adjust(hspace=0.5, wspace=0.3)\n",
        "  sns.boxplot(x = df[ticker])\n",
        "  ax.set_title(ticker.upper())\n",
        "  ax.set_xlabel(\"\")"
      ],
      "metadata": {
        "id": "YZrUzkuIDTVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Windspeed, Rainfall, Snowfall and Solar Radiation change wrt their seasons and hit their peaks only during their seasons and remain average during the others.\n",
        "*   These outlers might offer insight when predicting the target variable\n",
        "\n"
      ],
      "metadata": {
        "id": "IFZWLVPnDaEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Hot Encoding"
      ],
      "metadata": {
        "id": "-aA87-wZDneV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#categorical features are one hot encoded\n",
        "engineered_df = df.copy()\n",
        "for ftr in categorical_features:\n",
        "  engineered_df = pd.concat([pd.get_dummies(engineered_df[ftr],prefix = ftr, drop_first=True), engineered_df.drop(ftr, axis = 1)], axis =1)\n"
      ],
      "metadata": {
        "id": "h4ykMXO2DrpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "engineered_df.info()"
      ],
      "metadata": {
        "id": "GeU13NqwDuwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Split"
      ],
      "metadata": {
        "id": "rPzCp576D0TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary modules for Deploying models and Evaluating them\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, max_error\n",
        "from sklearn.linear_model import  LinearRegression, Lasso, Ridge\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR, LinearSVR\n",
        "from sklearn.neighbors import KNeighborsRegressor                                                                                                                                                                                                                                                #mahinisawesomemate\n",
        "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, GradientBoostingRegressor, RandomForestRegressor, VotingRegressor, StackingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler"
      ],
      "metadata": {
        "id": "BTiU9eSxD33v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting data into train and test set\n",
        "X,y = engineered_df.drop('Rented Bike Count', axis=1), engineered_df['Rented Bike Count']                                                                                                                                                                                                                                                #mahinisawesomemate\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size =0.2,  random_state=5)"
      ],
      "metadata": {
        "id": "xHWvD5kRD68c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "E-yPj0vFGt7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling"
      ],
      "metadata": {
        "id": "IBKBvGb5GzTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function to scale\n",
        "def do_scale(X_train, X_test, scaling_type = StandardScaler):\n",
        "  scaler = scaling_type()\n",
        "  scaler.fit(X_train)\n",
        "  X_train_scaled = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns)\n",
        "  X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)                                                                                                                                                                                                                                                #mahinisawesomemate\n",
        "  return X_train_scaled, X_test_scaled"
      ],
      "metadata": {
        "id": "GWAhSl5_HGF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "c8-X6GLSHoB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap"
      ],
      "metadata": {
        "id": "SjLRzpUcHptq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap"
      ],
      "metadata": {
        "id": "qAk33kCLHyGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dictionary that will store metrics for evaluated models\n",
        "#This will be converted DataFrame using display report function\n",
        "report = {\n",
        "    'model_type':[],\n",
        "    'model_name':[],                                                                                                                                                                                                                                                #mahinisawesomemate\n",
        "    'rmse':[],\n",
        "    'mae':[],\n",
        "    'R2':[],\n",
        "    'adjusted R2':[]\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "DFf5GemlHt91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to evaluate and update model and score\n",
        "def evaluate(modeltype, modelname, Model, X_train, y_train, X_test, y_test):\n",
        "  from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, max_error\n",
        "  #making sure the same model is not re-entered again\n",
        "  if modelname in report['model_name']:                                                                                                                                                                                                                                                #mahinisawesomemate\n",
        "    print(\"Prexisting Model\")\n",
        "    return 0\n",
        "  #making a copy to prevent accidental data changes\n",
        "  X_tr = X_train.copy()\n",
        "  X_te = X_test.copy()\n",
        "\n",
        "  #Fitting Model\n",
        "  Model.fit(X_tr, y_train)\n",
        "                                                                                                                                                                                                                                                #mahinisawesomemate\n",
        "  #Predicting Values from test set using model\n",
        "  y_pred = Model.predict(X_te)\n",
        "\n",
        "  #Model Evaluation\n",
        "\n",
        "  #Mean Absolute Error\n",
        "  mae = mean_absolute_error(y_test,y_pred)\n",
        "  report['mae'].append(mae) #Appending Metric\n",
        "\n",
        "  #R2 score\n",
        "  R2 = r2_score(y_test,y_pred)\n",
        "  report['R2'].append(R2) #Appending Metric\n",
        "\n",
        "  #Root Mean Square Error\n",
        "  rmse = np.sqrt(mean_squared_error(y_test,y_pred))\n",
        "  report['rmse'].append(rmse) #Appending Metric\n",
        "\n",
        "  #Adjusted R2 score\n",
        "  adj_r2=1-(1-R2)*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))\n",
        "  report['adjusted R2'].append(adj_r2) #Appending Metric\n",
        "\n",
        "  #Appending Model Details\n",
        "  report['model_name'].append(modelname)\n",
        "  report['model_type'].append(modeltype)\n",
        "\n",
        "  print(f\"\\n\\n\\n----------\\n\")\n",
        "\n",
        "  #Plotting Graph of observed vs predicted values\n",
        "  plt.figure(figsize=(20,10))\n",
        "  plt.plot((y_pred)[:100])\n",
        "  plt.plot((np.array(y_test)[:100]))\n",
        "  plt.legend([\"Predicted\",\"Actual\"])\n",
        "  plt.title(modelname)\n",
        "  plt.show()\n",
        "\n",
        "  print(f\"\\n\\n\\n----------\\n\")\n"
      ],
      "metadata": {
        "id": "2OKEEI_pH1tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#displays report in a dataframe\n",
        "def display_report():\n",
        "  return pd.DataFrame(report)"
      ],
      "metadata": {
        "id": "jNsclXlvH6Wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Models"
      ],
      "metadata": {
        "id": "XkZniRp3IFd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#installing catboost                                                                                                                                                                                                                                                #mahinisawesomemate\n",
        "!pip install catboost"
      ],
      "metadata": {
        "id": "zH1Ro9udIKIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostRegressor\n",
        "import lightgbm as lgb\n",
        "from xgboost import XGBRegressor"
      ],
      "metadata": {
        "id": "LZ3slrBGIPGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function that returns 3 arrays of model-functions, names and their details\n",
        "def get_models():\n",
        "  models, names, model_type = list(), list(), list()\n",
        "\n",
        "  # LinearReg\n",
        "  models.append(LinearRegression())\n",
        "  names.append('Linear Regression')\n",
        "  model_type.append('Linear')\n",
        "\n",
        "  #Lasso\n",
        "  models.append(Lasso(alpha =0.2))\n",
        "  names.append('Lasso Regression')\n",
        "  model_type.append('Regularized Linear (Lasso) ')\n",
        "\n",
        "  #Ridge\n",
        "  models.append(Ridge(alpha =0.5))\n",
        "  names.append('Ridge Regression')\n",
        "  model_type.append('Regularized Linear (Ridge)')\n",
        "\n",
        "  # DecisionTree\n",
        "  models.append((DecisionTreeRegressor()))\n",
        "  names.append('DecisionTree Regressor')\n",
        "  model_type.append('CART')\n",
        "\n",
        "  #RandomForest\n",
        "  models.append(RandomForestRegressor())\n",
        "  names.append('RandomForest Regressor')\n",
        "  model_type.append('Ensemble Method')\n",
        "\n",
        "  # GradientBoosting\n",
        "  models.append(GradientBoostingRegressor())\n",
        "  names.append('GradientBoosting Regressor')\n",
        "  model_type.append('Ensemble Method')\n",
        "\n",
        "  # CatBoosting\n",
        "  models.append(CatBoostRegressor(silent = True))\n",
        "  names.append('Cat Boosting Regressor')\n",
        "  model_type.append('Ensemble Method')\n",
        "\n",
        "  #Bagging\n",
        "  models.append(BaggingRegressor())\n",
        "  names.append('Bagging Regressor')\n",
        "  model_type.append('Ensemble Method')\n",
        "\n",
        "  #LightGBM Regressor\n",
        "  models.append(lgb.LGBMRegressor())\n",
        "  names.append('LightGBM Regressor')\n",
        "  model_type.append('Ensemble Method')\n",
        "\n",
        "  # KNN\n",
        "  models.append(KNeighborsRegressor())\n",
        "  names.append('K Neighbors Regressor')\n",
        "  model_type.append('Neighbours')\n",
        "\n",
        "\n",
        "  return models, names, model_type"
      ],
      "metadata": {
        "id": "8385L_VbIKjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment"
      ],
      "metadata": {
        "id": "e3LGftC1IZY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling\n",
        "X_train_scaled, X_test_scaled = do_scale(X_train,X_test)"
      ],
      "metadata": {
        "id": "ZDpuk-pCIVEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled.shape, X_test_scaled.shape"
      ],
      "metadata": {
        "id": "n1EiOWZeIcdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluating ML models"
      ],
      "metadata": {
        "id": "hLK9iuNfIisd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluating all modules in models and printing prediction graph\n",
        "Model, modelname, modeltype = get_models()\n",
        "for i in range(len(Model)):\n",
        "  evaluate(modeltype[i], modelname[i], Model[i], X_train_scaled , y_train, X_test_scaled,y_test)"
      ],
      "metadata": {
        "id": "wZLEB4r4Ie3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_report().sort_values('R2', ascending=False)"
      ],
      "metadata": {
        "id": "6PKRmpcJIpn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cat Boosting Regressor,LightGBM and Random Forest Regressor have emerged to be the best performing models with R2 scores of 0.923, 0.909 and 0.898"
      ],
      "metadata": {
        "id": "5okAuli0I02g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "SZupaoQYI4oY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CATBOOST"
      ],
      "metadata": {
        "id": "P7qBDzzMI7v1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
      ],
      "metadata": {
        "id": "I72mGMlhIuyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cbc = CatBoostRegressor(silent = True)\n",
        "\n",
        "#create the grid\n",
        "grid = {'max_depth': [1,3,5,10,12],\n",
        "        'n_estimators':[100,200,350,400]\n",
        "        }\n",
        "\n",
        "#Instantiate GridSearchCV\n",
        "gscv = GridSearchCV (estimator = cbc, param_grid = grid, scoring ='r2', cv = 3)\n",
        "\n",
        "#fit the model\n",
        "gscv.fit(X_train_scaled,y_train)\n",
        "print(gscv.best_estimator_)\n"
      ],
      "metadata": {
        "id": "jK3RlYCxJARY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#returns the best score\n",
        "print(gscv.best_score_)                                                                                                                                                                                                                                                #mahinisawesomemate\n",
        "#returns the best parameters\n",
        "print(gscv.best_params_)"
      ],
      "metadata": {
        "id": "zmHVwXq8JC27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation\n",
        "tuned_catboost = CatBoostRegressor(**gscv.best_params_, silent=True)\n",
        "evaluate(\"Ensemble Method\", \"TUNED CatBoost Model\", tuned_catboost, X_train_scaled , y_train, X_test_scaled,y_test)"
      ],
      "metadata": {
        "id": "ra-dfrnjJE7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_report().tail(1)"
      ],
      "metadata": {
        "id": "ts-o3XjjJH-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After tuning the parameters, CatBoosting's R2 scored has increased from 0.9235 to 0.9368"
      ],
      "metadata": {
        "id": "0syXKHjyLwi-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SHAP"
      ],
      "metadata": {
        "id": "aa3egcTTMI21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.TreeExplainer(gscv.best_estimator_)\n",
        "shap_values = explainer.shap_values(X_test_scaled)"
      ],
      "metadata": {
        "id": "_MVzalngLqJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.initjs()\n",
        "i = 4\n",
        "shap.force_plot(explainer.expected_value, shap_values[i], features=X_test_scaled.iloc[i], feature_names=X_train_scaled.columns)"
      ],
      "metadata": {
        "id": "turd68kUNHAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values, features= X_test_scaled, feature_names= X_test_scaled.columns, plot_type='bar')"
      ],
      "metadata": {
        "id": "WZFULdJrNOLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(23)\n",
        "index = (random.randint(0,len(X_test_scaled)))"
      ],
      "metadata": {
        "id": "HZm-OzpRNv-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LIME Explainability"
      ],
      "metadata": {
        "id": "audV3xnOOD5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lime"
      ],
      "metadata": {
        "id": "WX2LH_XNN6QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lime\n",
        "from lime.lime_tabular import LimeTabularExplainer"
      ],
      "metadata": {
        "id": "pITYgf4KOK-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names =list(X_train_scaled.columns)\n",
        "\n",
        "explainer = LimeTabularExplainer(np.array(X_train_scaled),\n",
        "    feature_names=feature_names,\n",
        "    mode = 'regression')"
      ],
      "metadata": {
        "id": "a9R_s259OOTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp = explainer.explain_instance(\n",
        "      data_row=X_test_scaled.iloc[index],\n",
        "      predict_fn= gscv.best_estimator_.predict\n",
        ")\n",
        "print(f\"-----------\\nACTUAL VALUE OBSERVED: {y_test.iloc[index]}\\n\")\n",
        "exp.show_in_notebook(show_table=True)"
      ],
      "metadata": {
        "id": "y-OdOWUnOQtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Random Forest"
      ],
      "metadata": {
        "id": "RjOo20oNOWEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfr = RandomForestRegressor()\n",
        "\n",
        "#create the grid\n",
        "grid = {'max_depth': [24,25,26],\n",
        "        'n_estimators':[375,400,425],\n",
        "        'max_samples':[0.5,0.6,0.8],\n",
        "        'max_features':[10,15,20]\n",
        "        }\n",
        "\n",
        "#Instantiate GridSearchCV\n",
        "gscv2 = GridSearchCV (estimator = rfr, param_grid = grid, scoring ='r2', cv = 3)                                                                                                                                                                                                                                                #mahinisawesomemate\n",
        "\n",
        "\n",
        "#fit the model\n",
        "gscv2.fit(X_train_scaled,y_train)                                                                                                                                                                                                                                                #mahinisawesomemate\n",
        "\n",
        "print(gscv2.best_estimator_)\n"
      ],
      "metadata": {
        "id": "5qcDT7hgOTYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#returns the best score\n",
        "print(gscv2.best_score_)                                                                                                                                                                                                                                                #mahinisawesomemate\n",
        "#returns the best parameters\n",
        "print(gscv2.best_params_)"
      ],
      "metadata": {
        "id": "grKLe-WuOZjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\"Ensemble Method\", \"TUNED Random Forest Model\", gscv2.best_estimator_, X_train_scaled , y_train, X_test_scaled,y_test)"
      ],
      "metadata": {
        "id": "MsB5Bf2hOcL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_report().tail(1)"
      ],
      "metadata": {
        "id": "x26iveA6Ofvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Upon Hyperparameter testing, the R2 score for Random Forest has increased from .0.896 to 0.903\n",
        "\n"
      ],
      "metadata": {
        "id": "Oij5bwILOzcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SHAP"
      ],
      "metadata": {
        "id": "35ZSpysYPV0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.TreeExplainer(gscv2.best_estimator_)\n",
        "shap_values = explainer.shap_values(X_test_scaled[:200])"
      ],
      "metadata": {
        "id": "fBLM8ykvOwyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.initjs()\n",
        "i = 4\n",
        "shap.force_plot(explainer.expected_value, shap_values[i], features=X_test_scaled.iloc[i], feature_names=X_train_scaled.columns)"
      ],
      "metadata": {
        "id": "vYbScVbyPW0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values, features= X_test_scaled, feature_names= X_test_scaled.columns, plot_type='bar')"
      ],
      "metadata": {
        "id": "Cuf_dvdGPaxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LIME Explainability"
      ],
      "metadata": {
        "id": "KGUKz1jKPtON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names =list(X_train_scaled.columns)\n",
        "\n",
        "explainer = LimeTabularExplainer(np.array(X_train_scaled),\n",
        "    feature_names=feature_names,\n",
        "    mode = 'regression')"
      ],
      "metadata": {
        "id": "TSjH8TR8Pt6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp = explainer.explain_instance(\n",
        "      data_row=X_test_scaled.iloc[index],\n",
        "      predict_fn= gscv2.best_estimator_.predict\n",
        ")\n",
        "print(f\"-----------\\nACTUAL VALUE OBSERVED: {y_test.iloc[index]}\\n\")\n",
        "exp.show_in_notebook(show_table=True)"
      ],
      "metadata": {
        "id": "TjxvSJWkPubb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Light GBM"
      ],
      "metadata": {
        "id": "CHHTrmR6P6zG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "\n",
        "\n",
        "        'max_depth': (19,20,25),\n",
        "        'n_estimators':[375,400,425],\n",
        "        'max_features':[10,15,20]\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "# Initialize a GridSearchCV -\n",
        "gscv3 = GridSearchCV(estimator=lgb.LGBMRegressor(), param_grid =  params, cv =  3,verbose=1)                                                                                                                                                                                                                                                #mahinisawesomemate\n",
        "\n",
        "\n",
        "# Train on training data-\n",
        "gscv3.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "X7V1yn9cPxjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#returns the best score\n",
        "print(gscv3.best_score_)                                                                                                                                                                                                                                                #mahinisawesomemate\n",
        "#returns the best parameters\n",
        "print(gscv3.best_params_)"
      ],
      "metadata": {
        "id": "_D2OqepiQCHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate\n",
        "evaluate(\"Ensemble Method\", \"TUNED LGBM\", gscv3.best_estimator_, X_train_scaled , y_train, X_test_scaled,y_test)"
      ],
      "metadata": {
        "id": "6_10x7GFQFA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_report().tail(1)"
      ],
      "metadata": {
        "id": "BYqLLbY7QJ5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tuned LightGBM regressor has produced a better performance than the tuned LightGBM regressor, from 0.909 to 0.921"
      ],
      "metadata": {
        "id": "XXp7Yfx7QX6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SHAP"
      ],
      "metadata": {
        "id": "tE8ZQcUkQbvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.TreeExplainer(gscv3.best_estimator_)\n",
        "shap_values = explainer.shap_values(X_test_scaled)"
      ],
      "metadata": {
        "id": "kP96JoNVQU3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.initjs()\n",
        "i = 4\n",
        "shap.force_plot(explainer.expected_value, shap_values[i], features=X_test_scaled.iloc[i], feature_names=X_train_scaled.columns)"
      ],
      "metadata": {
        "id": "b4Imdr5PQjUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values, features= X_test_scaled, feature_names= X_test_scaled.columns, plot_type='bar')"
      ],
      "metadata": {
        "id": "RAe3FEJLQljR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LIME Explainability"
      ],
      "metadata": {
        "id": "YQCikFg3Qrj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names =list(X_train_scaled.columns)\n",
        "\n",
        "explainer = LimeTabularExplainer(np.array(X_train_scaled),\n",
        "    feature_names=feature_names,\n",
        "    mode = 'regression')"
      ],
      "metadata": {
        "id": "xa351HQMQoTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp = explainer.explain_instance(\n",
        "      data_row=X_test_scaled.iloc[index],\n",
        "      predict_fn= gscv3.best_estimator_.predict\n",
        ")\n",
        "print(f\"-----------\\nACTUAL VALUE OBSERVED: {y_test.iloc[index]}\\n\")\n",
        "exp.show_in_notebook(show_table=True)"
      ],
      "metadata": {
        "id": "6x2Pqc2MQq67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stacking"
      ],
      "metadata": {
        "id": "KUo7o5noQ5Xe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, we are going to try and stack the top 3 best performing regressors and evaluate its performance against the best performing model"
      ],
      "metadata": {
        "id": "T5t9XirNQ-6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "level0 = list()\n",
        "level0.append(('LGBM', gscv3.best_estimator_)) #Light GBM                                                                                                                                                                                                                                                #mahinisawesomemate\n",
        "level0.append(('Random Forest', gscv2.best_estimator_)) #Tuned Random Forest Model\n",
        "level0.append(('Cat Boost', gscv.best_estimator_)) #Tuned CatBoost\n",
        "# define meta learner model\n",
        "level1 = LinearRegression()"
      ],
      "metadata": {
        "id": "SvIyi6dOQ2Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacking_model = StackingRegressor(estimators=level0, final_estimator=level1, cv=5, passthrough = True)"
      ],
      "metadata": {
        "id": "CVSlUNaVRB1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\"Ensemble Method\", \"STACKING Regressor\", stacking_model, X_train_scaled , y_train, X_test_scaled,y_test)\n"
      ],
      "metadata": {
        "id": "S76SJ6PhRF0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_report().tail(1)"
      ],
      "metadata": {
        "id": "1F_HjrSqRIen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Stacking all three top learners gives an R2 score of 0.9379\n",
        "*   The Stacked model has better R2 scores than the individual learners\n",
        "\n"
      ],
      "metadata": {
        "id": "0f89MuTfRPdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LIME Explainability"
      ],
      "metadata": {
        "id": "wyaoQbjwRZON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stacking_model.fit(X_train_scaled , y_train)\n",
        "\n",
        "feature_names =list(X_train_scaled.columns)\n",
        "\n",
        "explainer = LimeTabularExplainer(np.array(X_train_scaled),\n",
        "    feature_names=feature_names,\n",
        "    mode = 'regression')"
      ],
      "metadata": {
        "id": "WebRJNfCRMOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp = explainer.explain_instance(\n",
        "      data_row=X_test_scaled.iloc[index],\n",
        "      predict_fn= stacking_model.predict\n",
        ")\n",
        "print(f\"-----------\\nACTUAL VALUE OBSERVED: {y_test.iloc[index]}\\n\")\n",
        "exp.show_in_notebook(show_table=True)"
      ],
      "metadata": {
        "id": "d0BcsUlCRcsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Perfomance Report"
      ],
      "metadata": {
        "id": "s-QU33ELRh-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_report().sort_values('R2', ascending = False)"
      ],
      "metadata": {
        "id": "qUPcBXwGRfO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top performing models based on R2 scores are Stacking Regressor and Parameter tuned CatBoosting Regressor."
      ],
      "metadata": {
        "id": "zrFtdf6SRrPz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "u-l-kj3vR1Ch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Upon Exploratory Data Analysis, we found that the bike rentals follow an hourly trend where it hits the first peak in the morning and the highest peak later in the evening.\n",
        "\n",
        "*   We also found that these trends are prominent only during weekdays and working days, leading us to make a safe assumption that office-goers make a notable contribution to bike sharing demand.\n",
        "\n",
        "*   In addition, seasons were observed to have a notable effect on bike rentals with high traffic during summer and a significantly lower demand in winter.\n",
        "*   Upon training and evaluation of the machine learning models, the CatBoost model and the Stacked Ensemble of CatBoost, LightGBM and Random Forest models performed the best when evaluated using the R2 metric. They produced R2 scores of 0.9369 and 0.9380, with a root mean squared error of 162.01 and 160.59 respectively.\n",
        "\n",
        "\n",
        "*   It was found that the top performing models made predictions based on the weather and time of the day as high weightage was given to seasons, temperature recorded, solar radiation and hour of the day. This confirms the trends observed during the exploratory data analysis stage of the project.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FOV_pvITR6Xy"
      }
    }
  ]
}